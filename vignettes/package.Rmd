---
title: 'Designtools'
author: "Jesse Koops"
date: "`r Sys.Date()`"
output: 
  tufte::tufte_html:
    tufte_features: ["fonts", "italics"]
editor_options: 
  chunk_output_type: console
vignette: >
  %\VignetteIndexEntry{Designtools}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

<style>
pre{
width: 54% !important;
background: whitesmoke;
padding:4px;
}
</style>

```{r setup, include=FALSE}
library(knitr)
library(printr)
set.seed(123)
opts_chunk$set(tidy = FALSE, message=FALSE)

```

# Introduction

This package contains functions for test design and test administration planning. It is not aimed at item banking or parallel forms. As such it is assumed that the user is interested in making one or several tests that are in some way optimal. The package contains most common functionality for automatic test assembly with the exception of parallel forms. Some preliminary work has been done on a two stage MST design. 

# Pretests

We will assume we have a number of items which can optionally be grouped (e.g. in a reading text). We wish to make an connected design with a minimal number of booklets where each item appears in an equal number of booklets.  This produces a design that is easy to assemble, administer and analyse. The booklets are constructed by making sets of unique items and combining them into booklets.The design can optionally be balanced according to categorical variables, like a test matrix or estimated difficulty, so that the different booklets are 'alike'. 

Below we use a set of approx 200 items belonging to 52 reading texts of variable length. Each item has a category (know, apply, evaluate) and an estimated difficulty level (1,2,3).

```{r}
library(designtools)
library(dplyr)

nit = 203

items = tibble(item_id = sprintf('itm%03i',1:nit), 
               text_id = sample(paste0('text',1:60), nit, replace=TRUE),
               category = sample(c('know','apply','evaluate'), nit, TRUE, prob=c(3,2,1)),
               difficulty = sample(1:3, nit, TRUE, prob=c(1,2,1)))
```

For a given pretest we want to use a maximum of 30 items in a booklet.

```{r}
dsg = pretest_design(items, 
                     max_nit=30, 
                     balance = c('category','difficulty'),
                     friends = 'text_id')

head(dsg)
```

We can see that the result is a deceptively simple block design with `r n_distinct(dsg$booklet_id)` booklets.

```{r, fig.margin=TRUE, echo=FALSE}
library(ggplot2)
dsg$booklet_id = as.factor(dsg$booklet_id)
ggplot(dsg,aes(y=booklet_id,x=reorder(item_id,block))) +
    geom_tile(fill='gold2') +
    theme(axis.text.x=element_blank(),
          axis.ticks.x=element_blank()) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          panel.background = element_blank()) +
    xlab('items') + ylab('booklets') + ggtitle('block design')
```


Friend groups are guaranteed to not be broken up in booklets. Category and difficulty are balanced as best as possible. However, one can imagine that the degree to which this is possible depends on the number of variables, number of categories per variable and the presence and size of friend groups.



```{r, echo=FALSE}
pc = dsg %>%
  count(booklet_id, category) %>%
  group_by(booklet_id) %>%
  mutate(p = n/sum(n))

pd = dsg %>%
  count(booklet_id, difficulty) %>%
  group_by(booklet_id) %>%
  mutate(p = n/sum(n))

egg::ggarrange(
  ggplot(pc, aes(fill=category, y=p, x=booklet_id)) +
    geom_bar(stat='identity') +
    coord_flip() +
    ylab('proportion of items') +
    ggtitle('category'),
  
  ggplot(pd, aes(fill=difficulty, y=p, x=booklet_id)) +
    geom_bar(stat='identity') +
    coord_flip() +
    ylab('proportion of items') +
    ggtitle('difficulty'),
  
  nrow=1
)

```

We want to keep the design as simple as possible to minimize the potential for mistakes. It is also, especially for paper tests, a good idea to use only one test version per school. In case names are not filled out, front pages are missing or schools copy tests including barcodes, etcetera, it helps  to know that there is only one version in a school.

# Test assignment

This leads to an optimization problem, namely how do we assign test versions to schools so that the number of students assigned to each test version is as similar as possible? This problem is known as a multi-way partitioning problem which is np-hard. The algorithm that is employed at the moment is heuristic but performs reasonably well. We have `r n_distinct(dsg$booklet_id)` test versions and 100 schools of various sizes. 

```{r}
schools = tibble(school_id=sprintf('school%03i',1:100),
                 school_size = sample(10:60,100,replace=TRUE))

n_booklets = n_distinct(dsg$booklet_id)

asgn = schools %>%
  mutate(booklet = size_groups(school_size,n_booklets))

asgn %>%
  group_by(booklet) %>%
  summarise(n_schools = n(),
            n_students = sum(school_size))

```


# Linear test design

After succesful administration of a pre-test we now hopefully have some item parameters. Constructing a test involves a lot of guesswork. Most problematic is that usually we need to 'know' what the population distribution is for our actual test on the ability scale of the pretest. In some instances we can take a fairly educated guess.

We start with item parameters and some item properties.

```{r}
pars = tibble(item_id = sprintf('item%03i',1:300), 
              item_score = 1, beta=runif(300,-2,2))

items = tibble(item_id = sprintf('item%03i',1:300), 
               category = sample(c('know','apply','evaluate'),300,TRUE))

```

Next is a choice of what we want to optimize. The options are number of items (optionally weighted), information, or a random test. To this we can add any number of constraints. These can be:

* numbers or fractions of items of a specific type
* minimum information/maximum SEM at selected points on the ability scale
* a range of expected average pvalue (proportion correct)

In addition we can have items selected as groups, similar to the pretest design above. Below we optimize test information at $\theta = 0.5$.

```{r}
ds = test_design(items,
                 item_count(category=='know') == 40,
                 item_count(category=='apply') == 15,
                 item_count(category=='evaluate') == 20,
                 difficulty_constraint(0.6, 0.7),
                 objective = maximize_information(theta=0.5),
                 pars=pars)

count(ds, category)
```

We see that 75 items are selected according to the constraints. The resulting information function is plotted in the margin.

```{r, fig.margin=TRUE,fig.cap='Information function of the constructed test. The vertical line indicates the point of optimization'}
library(dexter)
plot(information(semi_join(pars,ds,by='item_id')), 
     from=-4,to=4,bty='l',
     xlab=expression(theta),ylab='information')

abline(v=0.5)
```


# Multi stage tests

Construction of MST tests is quite similar with one exception: the user has to supply a routing test. So to start we construct a routing module of 15 items.

```{r}
routing_test = test_design(items,
                           item_count(category=='know') >= 5,
                           item_count(category=='apply') >= 3,
                           item_count(category=='evaluate') >= 4,
                           item_count() == 15,
                           difficulty_constraint(0.6, 0.7),
                           objective = maximize_information(theta=c(-0.5,0.5)),
                           pars=pars)




```

Next we design an MST test by providing the routing module, the number of second stage modules and any other constraints. The constraints apply to each resulting booklet individually, i.e. to each combination of the routing module and the second stage module, with the exception of the difficulty constraint which applies to the individual modules by default, see the help for more details.

```{r}
ds = mst_design(items, 
                routing_module=routing_test,
                nmod = 3,
                item_count(category=='know') == 40,
                item_count(category=='apply') == 15,
                item_count(category=='evaluate') == 20,
                objective = maximize_information(theta=c(-1,0,1)),
                difficulty_constraint(.5,.7),
                population_density = dnorm,
                pars=pars)


head(ds$design)
```

The mst_design function returns a list containing a design and routing rules. For the mst design we have an experimental plot. The upper margin shows the expected ability distributions in each booklet (the division of the input population density according to the routing rules) while the main plot shows the information function. The dotted line shows the weighted sum of the booklet information (weighted according to the probability of making this booklet given theta). This is the function that is optimized in the mst_design function.

```{r}
plot_mst_design(ds,pars,type='info', populaton_density=dnorm, ref_lines=c(-1,0,1))
```

